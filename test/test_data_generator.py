#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ - ä¸ºå„ç§æµ‹è¯•åœºæ™¯ç”Ÿæˆæµ‹è¯•æ•°æ®
"""

import random
import string
from typing import List, Dict, Tuple

class TestDataGenerator:
    """æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨"""
    
    def __init__(self):
        # ä¸­æ–‡å¸¸ç”¨è¯æ±‡
        self.chinese_words = [
            "äººå·¥æ™ºèƒ½", "æœºå™¨å­¦ä¹ ", "æ·±åº¦å­¦ä¹ ", "ç¥ç»ç½‘ç»œ", "è‡ªç„¶è¯­è¨€å¤„ç†",
            "è®¡ç®—æœºç§‘å­¦", "æ•°æ®åˆ†æ", "ç®—æ³•", "æ¨¡å‹", "è®­ç»ƒ",
            "åŒ—äº¬", "ä¸Šæµ·", "å¹¿å·", "æ·±åœ³", "æ­å·", "å—äº¬", "æ­¦æ±‰",
            "æ¸…åå¤§å­¦", "åŒ—äº¬å¤§å­¦", "å¤æ—¦å¤§å­¦", "ä¸Šæµ·äº¤é€šå¤§å­¦", "æµ™æ±Ÿå¤§å­¦",
            "è‹¹æœå…¬å¸", "è°·æ­Œå…¬å¸", "å¾®è½¯å…¬å¸", "è…¾è®¯å…¬å¸", "é˜¿é‡Œå·´å·´",
            "å¼ ä¸‰", "æå››", "ç‹äº”", "èµµå…­", "é™ˆä¸ƒ", "åˆ˜å…«", "é»„ä¹"
        ]
        
        # æƒ…æ„Ÿè¯æ±‡
        self.positive_words = [
            "ä¼˜ç§€", "å‡ºè‰²", "å®Œç¾", "æ»¡æ„", "å–œæ¬¢", "æ¨è", "èµ", "å¥½è¯„",
            "æ£’", "ä¸é”™", "æ»¡åˆ†", "æƒŠè‰³", "è¶…èµ", "ç»™åŠ›", "ç‚¹èµ"
        ]
        
        self.negative_words = [
            "å·®åŠ²", "å¤±æœ›", "ç³Ÿç³•", "ä¸æ»¡", "è®¨åŒ", "åƒåœ¾", "å·®è¯„", "å‘",
            "çƒ‚", "æ— è¯­", "å´©æºƒ", "æ¶å¿ƒ", "æ„¤æ€’", "æŠ±æ€¨", "é€€è´§"
        ]
        
        self.neutral_words = [
            "ä¸€èˆ¬", "æ™®é€š", "æ­£å¸¸", "è¿˜è¡Œ", "å‡‘åˆ", "ä¸­ç­‰", "å¹³å¸¸", "æ ‡å‡†",
            "åŸºæœ¬", "å¸¸è§„", "é€‚ä¸­", "å¹³å‡", "ä¸­æ€§", "å®¢è§‚", "äº‹å®"
        ]
    
    def generate_basic_text_samples(self) -> List[Tuple[str, str]]:
        """ç”ŸæˆåŸºç¡€æ–‡æœ¬æµ‹è¯•æ ·æœ¬"""
        samples = []
        
        # 1. ç©ºæ–‡æœ¬
        samples.append(("ç©ºæ–‡æœ¬", ""))
        
        # 2. å•å­—ç¬¦
        samples.append(("å•å­—ç¬¦", "æµ‹"))
        
        # 3. çŸ­æ–‡æœ¬
        samples.append(("çŸ­æ–‡æœ¬", "è¿™æ˜¯ä¸€ä¸ªç®€å•çš„æµ‹è¯•æ–‡æœ¬ã€‚"))
        
        # 4. ä¸­ç­‰é•¿åº¦æ–‡æœ¬
        medium_text = "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨å¿«é€Ÿå‘å±•ï¼Œæ·±åº¦å­¦ä¹ å’Œæœºå™¨å­¦ä¹ åœ¨å„ä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ã€‚" * 5
        samples.append(("ä¸­ç­‰æ–‡æœ¬", medium_text))
        
        # 5. é•¿æ–‡æœ¬
        long_text = "éšç€ç§‘æŠ€çš„ä¸æ–­è¿›æ­¥ï¼Œäººå·¥æ™ºèƒ½å·²ç»æˆä¸ºå½“ä»Šæœ€çƒ­é—¨çš„æŠ€æœ¯é¢†åŸŸä¹‹ä¸€ã€‚" * 100
        samples.append(("é•¿æ–‡æœ¬", long_text))
        
        # 6. è¶…é•¿æ–‡æœ¬
        very_long_text = "è¿™æ˜¯ä¸€ä¸ªç”¨äºæµ‹è¯•ç³»ç»Ÿå¤„ç†èƒ½åŠ›çš„è¶…é•¿æ–‡æœ¬ã€‚" * 10000
        samples.append(("è¶…é•¿æ–‡æœ¬", very_long_text))
        
        # 7. ç‰¹æ®Šå­—ç¬¦æ–‡æœ¬
        special_text = "ğŸ˜€ğŸ‰ğŸ’»ğŸš€ Hello World! ä½ å¥½ä¸–ç•Œï¼@#$%^&*()_+-=[]{}|;':\",./<>?"
        samples.append(("ç‰¹æ®Šå­—ç¬¦", special_text))
        
        # 8. æ··åˆè¯­è¨€æ–‡æœ¬
        mixed_text = "This is English text. è¿™æ˜¯ä¸­æ–‡æ–‡æœ¬ã€‚ã“ã‚Œã¯æ—¥æœ¬èªã§ã™ã€‚"
        samples.append(("æ··åˆè¯­è¨€", mixed_text))
        
        # 9. æ•°å­—å’Œç¬¦å·
        number_text = "2023å¹´12æœˆ25æ—¥ï¼Œæ¸©åº¦-5Â°Cï¼Œä»·æ ¼ï¿¥199.99ï¼Œç”µè¯13800138000ã€‚"
        samples.append(("æ•°å­—ç¬¦å·", number_text))
        
        # 10. çº¯æ ‡ç‚¹ç¬¦å·
        punctuation_text = "ï¼@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰â€”â€”+{}|ï¼š"ã€Šã€‹ï¼Ÿ[]\\;',./"
        samples.append(("çº¯æ ‡ç‚¹", punctuation_text))
        
        return samples
    
    def generate_sentiment_test_data(self) -> List[Tuple[str, str, str]]:
        """ç”Ÿæˆæƒ…æ„Ÿåˆ†ææµ‹è¯•æ•°æ®"""
        test_data = []
        
        # ç§¯ææƒ…æ„Ÿæ ·æœ¬
        positive_samples = [
            "è¿™ä¸ªäº§å“çœŸçš„å¾ˆæ£’ï¼è´¨é‡å¾ˆå¥½ï¼ŒæœåŠ¡ä¹Ÿå¾ˆå‘¨åˆ°ï¼Œæˆ‘éå¸¸æ»¡æ„ï¼",
            "å¤ªå–œæ¬¢è¿™ä¸ªè®¾è®¡äº†ï¼Œç®€ç›´å®Œç¾ï¼Œå¼ºçƒˆæ¨èç»™å¤§å®¶ï¼",
            "ä½“éªŒè¶…çº§å¥½ï¼ŒåŠŸèƒ½å¼ºå¤§ï¼Œæ€§ä»·æ¯”å¾ˆé«˜ï¼Œäº”æ˜Ÿå¥½è¯„ï¼",
            "å®¢æœæ€åº¦å¾ˆå¥½ï¼Œè§£å†³é—®é¢˜å¾ˆåŠæ—¶ï¼Œç»™ä¸ªå¤§å¤§çš„èµï¼",
            "åŒ…è£…ç²¾ç¾ï¼Œç‰©æµå¿«é€Ÿï¼Œå•†å“è´¨é‡è¶…å‡ºé¢„æœŸï¼Œéå¸¸æ»¡æ„ï¼"
        ]
        
        for text in positive_samples:
            test_data.append(("ç§¯ææƒ…æ„Ÿ", text, "positive"))
        
        # æ¶ˆææƒ…æ„Ÿæ ·æœ¬
        negative_samples = [
            "è¿™ä¸ªæœåŠ¡å¤ªå·®äº†ï¼Œç­‰äº†å¾ˆä¹…éƒ½æ²¡æœ‰å›åº”ï¼Œå®Œå…¨ä¸æ¨èï¼",
            "è´¨é‡å¾ˆå·®ï¼Œç”¨äº†å‡ å¤©å°±åäº†ï¼Œæµªè´¹é’±ï¼Œå·®è¯„ï¼",
            "å®¢æœæ€åº¦æ¶åŠ£ï¼Œè§£å†³é—®é¢˜ä¸ç§¯æï¼Œéå¸¸å¤±æœ›ï¼",
            "ç‰©æµå¤ªæ…¢äº†ï¼ŒåŒ…è£…ä¹Ÿå¾ˆå·®ï¼Œå•†å“æœ‰æŸåï¼Œè¦æ±‚é€€è´§ï¼",
            "åŠŸèƒ½ä¸å¥½ç”¨ï¼Œç•Œé¢è®¾è®¡å¾ˆç³Ÿç³•ï¼Œå®Œå…¨ä¸ç¬¦åˆæè¿°ï¼"
        ]
        
        for text in negative_samples:
            test_data.append(("æ¶ˆææƒ…æ„Ÿ", text, "negative"))
        
        # ä¸­æ€§æƒ…æ„Ÿæ ·æœ¬
        neutral_samples = [
            "ä»Šå¤©å¤©æ°”ä¸é”™ï¼Œæ¸©åº¦é€‚ä¸­ï¼Œé€‚åˆå¤–å‡ºæ´»åŠ¨ã€‚",
            "è¿™æ˜¯ä¸€ä¸ªæ™®é€šçš„äº§å“ï¼ŒåŠŸèƒ½åŸºæœ¬æ»¡è¶³éœ€æ±‚ã€‚",
            "ä»·æ ¼åœ¨åˆç†èŒƒå›´å†…ï¼Œè´¨é‡ä¸€èˆ¬ï¼Œæ²¡æœ‰ç‰¹åˆ«çªå‡ºçš„åœ°æ–¹ã€‚",
            "æŒ‰ç…§è¯´æ˜ä¹¦æ“ä½œï¼ŒåŠŸèƒ½æ­£å¸¸ï¼Œç¬¦åˆåŸºæœ¬è¦æ±‚ã€‚",
            "æ”¶åˆ°å•†å“äº†ï¼ŒåŒ…è£…å®Œæ•´ï¼Œæ­£åœ¨è¯•ç”¨ä¸­ã€‚"
        ]
        
        for text in neutral_samples:
            test_data.append(("ä¸­æ€§æƒ…æ„Ÿ", text, "neutral"))
        
        return test_data
    
    def generate_entity_test_data(self) -> List[Tuple[str, str, List[Dict]]]:
        """ç”Ÿæˆå®ä½“è¯†åˆ«æµ‹è¯•æ•°æ®"""
        test_data = []
        
        # äººåã€åœ°åã€æœºæ„åæ··åˆæ–‡æœ¬
        text1 = "å¼ ä¸‰åœ¨åŒ—äº¬å¤§å­¦å­¦ä¹ è®¡ç®—æœºç§‘å­¦ï¼Œä»–æ¥è‡ªä¸Šæµ·å¸‚æµ¦ä¸œæ–°åŒºã€‚"
        entities1 = [
            {"text": "å¼ ä¸‰", "type": "PERSON"},
            {"text": "åŒ—äº¬å¤§å­¦", "type": "ORG"},
            {"text": "ä¸Šæµ·å¸‚", "type": "GPE"},
            {"text": "æµ¦ä¸œæ–°åŒº", "type": "GPE"}
        ]
        test_data.append(("åŸºç¡€å®ä½“", text1, entities1))
        
        # å…¬å¸å’Œäººå
        text2 = "è‹¹æœå…¬å¸çš„CEOè’‚å§†Â·åº“å…‹è®¿é—®äº†æ¸…åå¤§å­¦ï¼Œè®¨è®ºäººå·¥æ™ºèƒ½åˆä½œé¡¹ç›®ã€‚"
        entities2 = [
            {"text": "è‹¹æœå…¬å¸", "type": "ORG"},
            {"text": "è’‚å§†Â·åº“å…‹", "type": "PERSON"},
            {"text": "æ¸…åå¤§å­¦", "type": "ORG"}
        ]
        test_data.append(("å…¬å¸äººå", text2, entities2))
        
        # å¤šä¸ªæœºæ„
        text3 = "ä¸­å›½ç§‘å­¦é™¢å’Œå¾®è½¯å…¬å¸å°†åœ¨æ·±åœ³å»ºç«‹è”åˆå®éªŒå®¤ã€‚"
        entities3 = [
            {"text": "ä¸­å›½ç§‘å­¦é™¢", "type": "ORG"},
            {"text": "å¾®è½¯å…¬å¸", "type": "ORG"},
            {"text": "æ·±åœ³", "type": "GPE"}
        ]
        test_data.append(("å¤šæœºæ„", text3, entities3))
        
        # å¤æ‚å®ä½“æ–‡æœ¬
        text4 = "è…¾è®¯å…¬å¸åˆ›å§‹äººé©¬åŒ–è…¾åœ¨å¹¿å·ä¸¾åŠçš„AIå¤§ä¼šä¸Šè¡¨ç¤ºï¼Œå°†ä¸æ–¯å¦ç¦å¤§å­¦åˆä½œå¼€å‘æ–°çš„æœºå™¨å­¦ä¹ ç®—æ³•ã€‚"
        entities4 = [
            {"text": "è…¾è®¯å…¬å¸", "type": "ORG"},
            {"text": "é©¬åŒ–è…¾", "type": "PERSON"},
            {"text": "å¹¿å·", "type": "GPE"},
            {"text": "æ–¯å¦ç¦å¤§å­¦", "type": "ORG"}
        ]
        test_data.append(("å¤æ‚å®ä½“", text4, entities4))
        
        return test_data
    
    def generate_segmentation_test_data(self) -> List[Tuple[str, str]]:
        """ç”Ÿæˆåˆ†è¯æµ‹è¯•æ•°æ®"""
        test_data = []
        
        # åŸºç¡€åˆ†è¯
        test_data.append(("åŸºç¡€åˆ†è¯", "æˆ‘çˆ±åŒ—äº¬å¤©å®‰é—¨"))
        
        # ä¸“ä¸šæœ¯è¯­
        test_data.append(("ä¸“ä¸šæœ¯è¯­", "æœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„é‡è¦åˆ†æ”¯"))
        
        # äººååœ°å
        test_data.append(("äººååœ°å", "å¼ ä¸‰åœ¨åŒ—äº¬å¤§å­¦å­¦ä¹ "))
        
        # æ–°è¯å’Œç½‘ç»œç”¨è¯­
        test_data.append(("ç½‘ç»œç”¨è¯­", "è¿™ä¸ªAIæ¨¡å‹çœŸçš„å¾ˆç‰›é€¼ï¼ŒYYDSï¼"))
        
        # æ•°å­—å’Œè‹±æ–‡æ··åˆ
        test_data.append(("æ•°å­—è‹±æ–‡", "iPhone15çš„ä»·æ ¼æ˜¯5999å…ƒ"))
        
        # é•¿å¥å­
        test_data.append(("é•¿å¥å­", "éšç€äººå·¥æ™ºèƒ½æŠ€æœ¯çš„å¿«é€Ÿå‘å±•ï¼Œæœºå™¨å­¦ä¹ å’Œæ·±åº¦å­¦ä¹ åœ¨å›¾åƒè¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸéƒ½å–å¾—äº†é‡å¤§çªç ´"))
        
        return test_data
    
    def generate_summary_test_data(self) -> List[Tuple[str, str, str]]:
        """ç”Ÿæˆæ–‡æœ¬æ‘˜è¦æµ‹è¯•æ•°æ®"""
        test_data = []
        
        # æ–°é—»ç±»æ–‡æœ¬
        news_text = """
        è‹¹æœå…¬å¸ä»Šæ—¥å‘å¸ƒäº†æœ€æ–°çš„iPhone 15ç³»åˆ—æ‰‹æœºï¼Œæ­è½½äº†å…¨æ–°çš„A17èŠ¯ç‰‡ã€‚
        è¿™æ¬¾æ‰‹æœºåœ¨æ‘„å½±åŠŸèƒ½æ–¹é¢æœ‰æ˜¾è‘—æå‡ï¼Œæ”¯æŒ4Kè§†é¢‘å½•åˆ¶å’Œä¸“ä¸šçº§ç…§ç‰‡ç¼–è¾‘ã€‚
        æ–°çš„èŠ¯ç‰‡é‡‡ç”¨3çº³ç±³å·¥è‰ºåˆ¶é€ ï¼Œæ€§èƒ½æ¯”ä¸Šä¸€ä»£æå‡äº†20%ï¼ŒåŒæ—¶åŠŸè€—é™ä½äº†15%ã€‚
        è‹¹æœå…¬å¸CEOè¡¨ç¤ºï¼Œè¿™æ˜¯è¿„ä»Šä¸ºæ­¢æœ€å…ˆè¿›çš„iPhoneäº§å“ã€‚
        é¢„è®¡è¿™æ¬¾æ‰‹æœºå°†åœ¨ä¸‹ä¸ªæœˆæ­£å¼ä¸Šå¸‚ï¼Œèµ·å”®ä»·ä¸º999ç¾å…ƒã€‚
        åˆ†æå¸ˆè®¤ä¸ºï¼Œæ–°iPhoneå°†å¸®åŠ©è‹¹æœåœ¨ç«äº‰æ¿€çƒˆçš„æ™ºèƒ½æ‰‹æœºå¸‚åœºä¸­ä¿æŒé¢†å…ˆåœ°ä½ã€‚
        """
        test_data.append(("æ–°é—»æ–‡æœ¬", news_text.strip(), "è‹¹æœiPhoneæ–°å“å‘å¸ƒ"))
        
        # æŠ€æœ¯æ–‡æ¡£
        tech_text = """
        æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªå­é¢†åŸŸï¼Œå®ƒåŸºäºäººå·¥ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ å’Œå†³ç­–ã€‚
        æ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸åŒ…å«å¤šä¸ªéšè—å±‚ï¼Œæ¯ä¸€å±‚éƒ½èƒ½å­¦ä¹ æ•°æ®çš„ä¸åŒç‰¹å¾ã€‚
        å·ç§¯ç¥ç»ç½‘ç»œï¼ˆCNNï¼‰ç‰¹åˆ«é€‚ç”¨äºå›¾åƒå¤„ç†ä»»åŠ¡ï¼Œè€Œå¾ªç¯ç¥ç»ç½‘ç»œï¼ˆRNNï¼‰åˆ™æ“…é•¿å¤„ç†åºåˆ—æ•°æ®ã€‚
        è¿‘å¹´æ¥ï¼ŒTransformeræ¶æ„çš„å‡ºç°é©å‘½æ€§åœ°æ”¹å˜äº†è‡ªç„¶è¯­è¨€å¤„ç†é¢†åŸŸã€‚
        æ·±åº¦å­¦ä¹ åœ¨è®¡ç®—æœºè§†è§‰ã€è¯­éŸ³è¯†åˆ«ã€è‡ªç„¶è¯­è¨€å¤„ç†ç­‰é¢†åŸŸéƒ½å–å¾—äº†çªç ´æ€§è¿›å±•ã€‚
        ç„¶è€Œï¼Œæ·±åº¦å­¦ä¹ æ¨¡å‹é€šå¸¸éœ€è¦å¤§é‡çš„è®­ç»ƒæ•°æ®å’Œè®¡ç®—èµ„æºã€‚
        """
        test_data.append(("æŠ€æœ¯æ–‡æ¡£", tech_text.strip(), "æ·±åº¦å­¦ä¹ æŠ€æœ¯æ¦‚è¿°"))
        
        # å­¦æœ¯è®ºæ–‡æ‘˜è¦
        academic_text = """
        æœ¬ç ”ç©¶æå‡ºäº†ä¸€ç§æ–°çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œç”¨äºæ”¹è¿›Transformeræ¨¡å‹åœ¨é•¿åºåˆ—å¤„ç†ä¸­çš„æ€§èƒ½ã€‚
        ä¼ ç»Ÿçš„è‡ªæ³¨æ„åŠ›æœºåˆ¶åœ¨å¤„ç†é•¿åºåˆ—æ—¶å­˜åœ¨è®¡ç®—å¤æ‚åº¦è¿‡é«˜çš„é—®é¢˜ã€‚
        æˆ‘ä»¬çš„æ–¹æ³•é€šè¿‡å¼•å…¥ç¨€ç–æ³¨æ„åŠ›æ¨¡å¼ï¼Œå°†è®¡ç®—å¤æ‚åº¦ä»O(nÂ²)é™ä½åˆ°O(n log n)ã€‚
        å®éªŒç»“æœè¡¨æ˜ï¼Œåœ¨å¤šä¸ªè‡ªç„¶è¯­è¨€å¤„ç†ä»»åŠ¡ä¸Šï¼Œæˆ‘ä»¬çš„æ–¹æ³•éƒ½å–å¾—äº†æ˜¾è‘—çš„æ€§èƒ½æå‡ã€‚
        ç‰¹åˆ«æ˜¯åœ¨æ–‡æ¡£çº§åˆ«çš„æœºå™¨ç¿»è¯‘ä»»åŠ¡ä¸­ï¼ŒBLEUåˆ†æ•°æé«˜äº†3.2ä¸ªç‚¹ã€‚
        è¿™ç§æ–¹æ³•ä¸ºå¤„ç†é•¿åºåˆ—çš„Transformeræ¨¡å‹æä¾›äº†ä¸€ä¸ªæœ‰æ•ˆçš„è§£å†³æ–¹æ¡ˆã€‚
        """
        test_data.append(("å­¦æœ¯è®ºæ–‡", academic_text.strip(), "æ”¹è¿›çš„Transformeræ³¨æ„åŠ›æœºåˆ¶"))
        
        return test_data
    
    def generate_performance_test_data(self) -> Dict[str, str]:
        """ç”Ÿæˆæ€§èƒ½æµ‹è¯•æ•°æ®"""
        test_data = {}
        
        # å°æ–‡æœ¬ (< 1000å­—ç¬¦)
        small_text = "äººå·¥æ™ºèƒ½æŠ€æœ¯æ­£åœ¨æ”¹å˜æˆ‘ä»¬çš„ç”Ÿæ´»ã€‚" * 20
        test_data["å°æ–‡æœ¬"] = small_text
        
        # ä¸­ç­‰æ–‡æœ¬ (1000-10000å­—ç¬¦)
        medium_text = "éšç€ç§‘æŠ€çš„å‘å±•ï¼Œäººå·¥æ™ºèƒ½åœ¨å„ä¸ªé¢†åŸŸéƒ½æœ‰å¹¿æ³›åº”ç”¨ï¼ŒåŒ…æ‹¬åŒ»ç–—ã€æ•™è‚²ã€é‡‘èç­‰ã€‚" * 100
        test_data["ä¸­ç­‰æ–‡æœ¬"] = medium_text
        
        # å¤§æ–‡æœ¬ (10000-50000å­—ç¬¦)
        large_text = "æ·±åº¦å­¦ä¹ æ˜¯æœºå™¨å­¦ä¹ çš„ä¸€ä¸ªé‡è¦åˆ†æ”¯ï¼Œå®ƒæ¨¡æ‹Ÿäººè„‘ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†ã€‚" * 500
        test_data["å¤§æ–‡æœ¬"] = large_text
        
        # è¶…å¤§æ–‡æœ¬ (50000-200000å­—ç¬¦)
        very_large_text = "è‡ªç„¶è¯­è¨€å¤„ç†æ˜¯äººå·¥æ™ºèƒ½é¢†åŸŸçš„ä¸€ä¸ªé‡è¦ç ”ç©¶æ–¹å‘ã€‚" * 2000
        test_data["è¶…å¤§æ–‡æœ¬"] = very_large_text
        
        return test_data
    
    def generate_edge_case_data(self) -> List[Tuple[str, str]]:
        """ç”Ÿæˆè¾¹ç•Œæƒ…å†µæµ‹è¯•æ•°æ®"""
        edge_cases = []
        
        # 1. åªæœ‰æ ‡ç‚¹ç¬¦å·
        edge_cases.append(("çº¯æ ‡ç‚¹", "ï¼@#ï¿¥%â€¦â€¦&*ï¼ˆï¼‰"))
        
        # 2. åªæœ‰æ•°å­—
        edge_cases.append(("çº¯æ•°å­—", "1234567890"))
        
        # 3. åªæœ‰è‹±æ–‡
        edge_cases.append(("çº¯è‹±æ–‡", "Hello World This is a test"))
        
        # 4. åªæœ‰ç©ºæ ¼
        edge_cases.append(("çº¯ç©ºæ ¼", "     "))
        
        # 5. é‡å¤å­—ç¬¦
        edge_cases.append(("é‡å¤å­—ç¬¦", "æµ‹è¯•æµ‹è¯•æµ‹è¯•æµ‹è¯•æµ‹è¯•"))
        
        # 6. å•ä¸ªé•¿è¯
        edge_cases.append(("è¶…é•¿è¯", "äººå·¥æ™ºèƒ½æœºå™¨å­¦ä¹ æ·±åº¦å­¦ä¹ è‡ªç„¶è¯­è¨€å¤„ç†è®¡ç®—æœºè§†è§‰"))
        
        # 7. æ¢è¡Œç¬¦å’Œåˆ¶è¡¨ç¬¦
        edge_cases.append(("æ§åˆ¶å­—ç¬¦", "ç¬¬ä¸€è¡Œ\nç¬¬äºŒè¡Œ\tåˆ¶è¡¨ç¬¦"))
        
        # 8. Unicodeç‰¹æ®Šå­—ç¬¦
        edge_cases.append(("Unicode", "Î±Î²Î³Î´Îµä¸­æ–‡ğŸŒŸğŸ’«â­"))
        
        # 9. HTMLæ ‡ç­¾ï¼ˆåº”è¯¥è¢«å¤„ç†ä¸ºæ™®é€šæ–‡æœ¬ï¼‰
        edge_cases.append(("HTMLæ ‡ç­¾", "<div>è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•</div>"))
        
        # 10. æçŸ­æ–‡æœ¬
        edge_cases.append(("æçŸ­æ–‡æœ¬", "æµ‹"))
        
        return edge_cases
    
    def save_test_data_to_files(self):
        """å°†æµ‹è¯•æ•°æ®ä¿å­˜åˆ°æ–‡ä»¶"""
        import json
        
        # ä¿å­˜å„ç±»æµ‹è¯•æ•°æ®
        all_data = {
            "basic_samples": self.generate_basic_text_samples(),
            "sentiment_data": self.generate_sentiment_test_data(),
            "entity_data": self.generate_entity_test_data(),
            "segmentation_data": self.generate_segmentation_test_data(),
            "summary_data": self.generate_summary_test_data(),
            "performance_data": self.generate_performance_test_data(),
            "edge_cases": self.generate_edge_case_data()
        }
        
        with open('test/test_data.json', 'w', encoding='utf-8') as f:
            json.dump(all_data, f, ensure_ascii=False, indent=2)
        
        print("æµ‹è¯•æ•°æ®å·²ä¿å­˜åˆ° test/test_data.json")

if __name__ == "__main__":
    generator = TestDataGenerator()
    
    print("=== æµ‹è¯•æ•°æ®ç”Ÿæˆå™¨ ===\n")
    
    # ç”Ÿæˆå¹¶æ˜¾ç¤ºå„ç±»æµ‹è¯•æ•°æ®
    print("1. åŸºç¡€æ–‡æœ¬æ ·æœ¬:")
    for name, text in generator.generate_basic_text_samples()[:5]:
        print(f"   {name}: {text[:50]}{'...' if len(text) > 50 else ''}")
    
    print("\n2. æƒ…æ„Ÿåˆ†ææµ‹è¯•æ•°æ®:")
    for category, text, sentiment in generator.generate_sentiment_test_data()[:3]:
        print(f"   {category} ({sentiment}): {text[:50]}...")
    
    print("\n3. å®ä½“è¯†åˆ«æµ‹è¯•æ•°æ®:")
    for name, text, entities in generator.generate_entity_test_data()[:2]:
        entity_names = [e['text'] for e in entities]
        print(f"   {name}: {text}")
        print(f"   å®ä½“: {entity_names}")
    
    print("\n4. è¾¹ç•Œæƒ…å†µæµ‹è¯•æ•°æ®:")
    for name, text in generator.generate_edge_case_data()[:5]:
        print(f"   {name}: {repr(text)}")
    
    # ä¿å­˜æ‰€æœ‰æµ‹è¯•æ•°æ®
    generator.save_test_data_to_files()
